{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Keras.NET, 3.8.5</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Keras.NET\"\n",
    "\n",
    "using Keras.Datasets;\n",
    "using System;\n",
    "using Numpy;\n",
    "using Keras.Models;\n",
    "using Keras.Layers;\n",
    "using Keras.PreProcessing.sequence;\n",
    "using Keras.PreProcessing.Text;\n",
    "using System.Linq;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public static void Run()\n",
    "        {\n",
    "            //Load IMDb dataset\n",
    "            var ((x_train, y_train), (x_test, y_test)) = IMDB.LoadData();\n",
    "\n",
    "            var X = np.concatenate(new NDarray[] { x_train, x_test }, axis: 0);\n",
    "            var Y = np.concatenate(new NDarray[] { y_train, y_test }, axis: 0);\n",
    "\n",
    "            Console.WriteLine(\"Shape of X: \" + X.shape);\n",
    "            Console.WriteLine(\"Shape of Y: \" + Y.shape);\n",
    "\n",
    "            //We can get an idea of the total number of unique words in the dataset.\n",
    "            Console.WriteLine(\"Number of words: \");\n",
    "            var hstack = np.hstack(new NDarray[] { X });\n",
    "            //var unique = hstack.unique();\n",
    "            //Console.WriteLine(np.unique(np.hstack(new NDarray[] { X })).Item1);\n",
    "\n",
    "            // Load the dataset but only keep the top n words, zero the rest\n",
    "            int top_words = 5000;\n",
    "            ((x_train, y_train), (x_test, y_test)) = IMDB.LoadData(num_words: top_words);\n",
    "\n",
    "            int max_words = 500;\n",
    "            x_train = SequenceUtil.PadSequences(x_train, maxlen: max_words);\n",
    "            x_test = SequenceUtil.PadSequences(x_test, maxlen: max_words);\n",
    "\n",
    "            //Create model\n",
    "            Sequential model = new Sequential();\n",
    "            model.Add(new Embedding(top_words, 32, input_length: max_words));\n",
    "            model.Add(new Conv1D(filters: 32, kernel_size: 3, padding: \"same\", activation: \"relu\"));\n",
    "            model.Add(new MaxPooling1D(pool_size: 2));\n",
    "            model.Add(new Flatten());\n",
    "            model.Add(new Dense(250, activation: \"relu\"));\n",
    "            model.Add(new Dense(1, activation: \"sigmoid\"));\n",
    "\n",
    "            model.Compile(loss: \"binary_crossentropy\", optimizer: \"adam\", metrics: new string[] { \"accuracy\" });\n",
    "            model.Summary();\n",
    "\n",
    "            // Fit the model\n",
    "            model.Fit(x_train, y_train, validation_data: new NDarray[] { x_test, y_test }, epochs: 10, batch_size: 128, verbose: 2);\n",
    "            // Final evaluation of the model\n",
    "            var scores = model.Evaluate(x_test, y_test, verbose: 0);\n",
    "            Console.WriteLine(\"Accuracy: \" + (scores[1] * 100));\n",
    "\n",
    "            model.Save(\"model-imdb.h5\");\n",
    "            //model.SaveTensorflowJSFormat(\"./\");\n",
    "        }\n",
    "\n",
    "        public static void Predict(string text)\n",
    "        {\n",
    "            var model = Sequential.LoadModel(\"model-imdb.h5\");\n",
    "            string result = \"\";\n",
    "\n",
    "            var indexes = IMDB.GetWordIndex();\n",
    "\n",
    "            string[] words = TextUtil.TextToWordSequence(text);\n",
    "            float[] tokens = words.Select(i => ((float)indexes[i])).ToArray();\n",
    "\n",
    "            NDarray x = np.array(tokens);\n",
    "            x = x.reshape(1, x.shape[0]);\n",
    "            x = SequenceUtil.PadSequences(x, maxlen: 500);\n",
    "            var y = model.Predict(x);\n",
    "            var binary = y[0].item<float>();\n",
    "            Console.WriteLine(y[0].item<float>());\n",
    "            result = binary < 0.7 ? \"Negative\" : \"Positive\";\n",
    "            Console.WriteLine(\"Sentiment for \\\"{0}\\\": {1}\", text, result);\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59822756\n",
      "Sentiment for \"I hate you\": Negative\n",
      "0.96466196\n",
      "Sentiment for \"I care about you\": Positive\n"
     ]
    }
   ],
   "source": [
    "//Run();\n",
    "Predict(\"I hate you\");\n",
    "Predict(\"I care about you\");"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
